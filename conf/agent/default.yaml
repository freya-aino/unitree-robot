observation_size: ${environment.observation_size}
action_size: ${environment.action_size}
train_sequence_length: ${training.unroll_length}

network_hidden_size: ~
num_hidden_layers: ~

lambda_: ~
epsilon: ~
discounting: ~
reward_scaling: ~
moving_average_window_size: ~
# softplus_sharpness_factor: ~ # higher beta make the softplus for the logit std fall of more sharply, with a Tanh activation function this means it increases possible -log(p)

policy_loss_scale: ~
value_loss_scale: ~
entropy_loss_scale: ~