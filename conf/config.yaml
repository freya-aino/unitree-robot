defaults:
  - _self_
  - environment: go2-flat_terrain-menagerie
  - experiment: standing_up-v1
  - agent: ppo-v1

optimizer:
  lr: 0.0
lr_scheduler:
  T_0: 80 # number of epochs for the first restart
  T_mult: 1 # a factor increases T_i after a restart (i.e.: 2 means double the number of epochs after each restart)
  eta_min: 0.0

# environment settings
sim_frames_per_step: 5
mujoco_timestep: 0.002 # 0.0005 - 0.005

# training settings
total_timesteps: 2e6
num_parallel_environments: 64 # for 8GB VRAM 100-200 is good, depends of the unroll length, and model size
batch_unroll_length: 500
# a "batch" is total_timesteps / (num_parallel_environments * batch_unroll_length)
train_epochs_per_batch: 10 # number of epochs per batch of data

mlflow_tracking_uri: ~ # "sqlite:///mlflow.db"

device: "cuda" # "cpu" or "cuda"
max_gradient_norm: 1.0 # gradients are clipped to this value to avoid large updates
random_seed: 0
validation_interval: 5
experiment_name: "standing_up"
xla_gpu_memory_fraction: 0.5 # Fraction of GPU memory to allocate when using XLA on GPU for jax